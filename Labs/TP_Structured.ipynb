{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://raw.githubusercontent.com/DivLoic/mdd-structured-streaming/master/resources/intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Structured Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/DivLoic/mdd-structured-streaming/master/resources/unbounded.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DÃ©velopper une application de Machine Learning en moins de 30 min - Alban Phelip & Mouloud Lounaci](https://youtu.be/iZoVwBDYyMU)\n",
    "![](https://raw.githubusercontent.com/DivLoic/mdd-structured-streaming/master/resources/twitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les sources :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/DivLoic/mdd-structured-streaming/master/resources/source.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val BROKER_HOST = \"172.16.41.136\"\n",
    "val BROKER_PORT = \"9092\"\n",
    "val S3_DIR = \"/mnt/moisdeladata/\"\n",
    "val TOPIC = \"twitter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "println(\"***\" * 30)\n",
    "println(\"*\")\n",
    "println(s\"* \\t BROKER_HOST: $BROKER_HOST\")\n",
    "println(s\"* \\t BROKER_PORT: $BROKER_PORT\")\n",
    "println(s\"* \\t S3_DIR NAME: $S3_DIR\")\n",
    "println(s\"* \\t TOPIC NAME : $TOPIC\")\n",
    "println(\"*\")\n",
    "println(\"***\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * step 1: read from the source\n",
    " */\n",
    "\n",
    "val df: DataFrame = spark.readStream.format(\"kafka\")\n",
    "    \n",
    "    .option(\"kafka.bootstrap.servers\", s\"$BROKER_HOST:$BROKER_PORT\")\n",
    "\n",
    "    .option(\"subscribe\", TOPIC) // list or regex\n",
    "  \n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.getClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les transformations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "println(\"get_json_object(col: Column, path: String): Column -- \\\"json string\\\"\")\n",
    "println()\n",
    "println(\"from_json(col: Column, schema: StructType): Column  -- \\\"struct type\\\"\")\n",
    "println()\n",
    "println(\"to_json(col: Column): Column  -- \\\"json string\\\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kafka-connect-twitter : `{\"schema\": {}, \"payload\": {}}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * step 2: extract the payload\n",
    " */\n",
    "\n",
    "val dfPayload = df.withColumn(\n",
    "    \"payload\",\n",
    "    get_json_object(\n",
    "        $\"value\".cast(StringType), \n",
    "        \"$.payload\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfPayload.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```| <topic> | <timestamp> | {\"id\": 12345, \"user\": \"info\", ...} |```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * step 3: build a apply a schema\n",
    " */\n",
    "\n",
    "val ex_schema = new StructType(\n",
    "    Array(\n",
    "        StructField(\"id\", StringType),\n",
    "        StructField(\"media\", StringType),\n",
    "        StructField(\"text\", StringType, false)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfPayload.select(\n",
    "    \n",
    "    $\"topic\",\n",
    "    $\"timestamp\",\n",
    "    from_json($\"payload\", ex_schema) as 'tweet\n",
    "    \n",
    ").printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfStructured.printSchema\u001c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "root\n",
    " |-- topic: string (nullable = true)\n",
    " |-- timestamp: timestamp (nullable = true)\n",
    " |-- tweet: struct (nullable = true)\n",
    " |    |-- id: string (nullable = true)\n",
    " |    |-- text: string (nullable = false)\n",
    " |    |-- created_at: string (nullable = true)\n",
    " |    |-- is_retweet: boolean (nullable = true)\n",
    " |    |-- media: array (nullable = true)\n",
    " |    |    |-- element: string (containsNull = false)\n",
    " |    |-- user: struct (nullable = true)\n",
    " |    |    |-- id: long (nullable = false)\n",
    " |    |    |-- location: string (nullable = true)\n",
    " |    |    |-- verified: boolean (nullable = true)\n",
    " |    |    |-- screen_name: string (nullable = true)\n",
    " |    |-- entities: struct (nullable = true)\n",
    " |    |    |-- hashtags: array (nullable = true)\n",
    " |    |    |    |-- element: struct (containsNull = false)\n",
    " |    |    |    |    |-- text: string (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * step 4: flatten the frame\n",
    " */\n",
    "\n",
    "val dfTweets: DataFrame = dfStructured.select(\n",
    "    $\"topic\",\n",
    "    $\"timestamp\",\n",
    "    $\"tweet.id\" as \"tweet_id\",\n",
    "    $\"tweet.text\" as \"text\",\n",
    "    $\"tweet.is_retweet\" as \"is_retweet\",\n",
    "    substring($\"tweet.created_at\", 0, 23) as \"created_at\",\n",
    "    unix_timestamp(\n",
    "      substring($\"tweet.created_at\", 0, 23), \n",
    "      \"yyyy-MM-dd'T'HH:mm:ss.S\"\n",
    "    ).cast(TimestampType) as \"creation_time\",\n",
    "    $\"tweet.user.id\" as \"user_id\",\n",
    "    $\"tweet.user.verified\" as \"verified\",\n",
    "    $\"tweet.user.location\" as \"location\",\n",
    "    $\"tweet.user.screen_name\" as \"screen\",\n",
    "    $\"tweet.entities.hashtags.text\" as \"hashtags\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTweets.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "root\n",
    " |-- topic: string (nullable = true)\n",
    " |-- timestamp: timestamp (nullable = true)\n",
    " |-- tweet_id: string (nullable = true)\n",
    " |-- text: string (nullable = true)\n",
    " |-- is_retweet: boolean (nullable = true)\n",
    " |-- created_at: string (nullable = true)\n",
    " |-- creation_time: timestamp (nullable = true)\n",
    " |-- user_id: long (nullable = true)\n",
    " |-- verified: boolean (nullable = true)\n",
    " |-- location: string (nullable = true)\n",
    " |-- screen: string (nullable = true)\n",
    " |-- hashtags: array (nullable = true)\n",
    " |    |-- element: string (containsNull = false)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * step 5: filter, join & display\n",
    " */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTweets.createOrReplaceTempView(\"all_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTweets\n",
    "\n",
    ".filter(size($\"hashtags\") >= 4)\n",
    "\n",
    ".createOrReplaceTempView(\"all_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val ref = Seq(\n",
    "  \n",
    "  (\"25073877\", \"@realDonaldTrump\", \"target1\"),\n",
    "  (\"52544275\", \"@IvankaTrump\", \"target2\"),\n",
    "  (\"822215679726100480\", \"@POTUS\", \"target3\"),\n",
    "  (\"22203756\", \"@mike_pence\", \"target4\"),\n",
    "  (\"<your-id>\", \"@<your-name>\", \"target5\")\n",
    "  \n",
    ").toDF(\"profile_id\", \"name\", \"target\")\n",
    "\n",
    "display(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTweets\n",
    "\n",
    ".join(ref, dfTweets(\"user_id\") === ref(\"profile_id\"))\n",
    "\n",
    ".createOrReplaceTempView(\"known_users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/** ml **/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val finalColumns = Seq(\"text\", \"timestamp\", \"creation_time\", \"hashtags\", \"location\")\n",
    "val dfLive = dfTweets.filter(size($\"hashtags\") <= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val model: PipelineModel = PipelineModel.read.load(s\"$S3_DIR/models/trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val dfPrediction: DataFrame = model.transform(dfLive) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfPrediction.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "root\n",
    " |-- topic: string (nullable = true)\n",
    " |-- timestamp: timestamp (nullable = true)\n",
    " |-- tweet_id: string (nullable = true)\n",
    " |-- text: string (nullable = true)\n",
    " |-- is_retweet: boolean (nullable = true)\n",
    " |-- created_at: string (nullable = true)\n",
    " |-- creation_time: timestamp (nullable = true)\n",
    " |-- user_id: long (nullable = true)\n",
    " |-- verified: boolean (nullable = true)\n",
    " |-- location: string (nullable = true)\n",
    " |-- screen: string (nullable = true)\n",
    " |-- hashtags: array (nullable = true)\n",
    " |    |-- element: string (containsNull = false)\n",
    " |-- token_raw: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- ngram: array (nullable = true)\n",
    " |    |-- element: string (containsNull = false)\n",
    " |-- tf: vector (nullable = true)\n",
    " |-- idf: vector (nullable = true)\n",
    " |-- rawPrediction: vector (nullable = true)\n",
    " |-- probability: vector (nullable = true)\n",
    " |-- prediction: double (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(dfPrediction.select(\"prediction\", finalColumns:_*))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/DivLoic/mdd-structured-streaming/master/resources/final_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * step 7: write to the sink\n",
    " */"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/DivLoic/mdd-structured-streaming/master/resources/sink.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scala.concurrent.duration._\n",
    "import org.apache.spark.sql.streaming.{OutputMode, ProcessingTime, StreamingQuery}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%fs ls /mnt/moisdeladata/data/tweets/prediction/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfPrediction.select(\"prediction\", finalColumns:_*)\n",
    "\n",
    "  .writeStream.format(\"parquet\")\n",
    "  \n",
    "  .option(\"path\", s\"$S3_DIR/data/tweets/prediction/table/\")\n",
    "  \n",
    "  .option(\"checkpointLocation\", s\"$S3_DIR/checkpoints/prediction/\")\n",
    "  \n",
    "  .trigger(ProcessingTime(0.5 seconds))\n",
    "  \n",
    "  .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%fs ls /mnt/moisdeladata/data/tweets/prediction/`\n",
    "```\n",
    "    - part-00001-16dbff53-e686-4a57-a18a-26ca706034ad.snappy.parquet\n",
    "    - part-00001-2b8afcb1-37ab-43c2-8026-b5ad03dfe22f.snappy.parquet\n",
    "    - part-00001-3474a0e2-6e56-4073-9fe6-790c4b5c65f6.snappy.parquet\n",
    "    - part-00001-686a7735-41a4-43c7-a1af-a86461d2b75f.snappy.parquet\n",
    "    - ...\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/mnt/moisdeladata/data/tweets/prediction/table/\").size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: \n",
    "- *[Apache Spark](http://spark.apache.org) documentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "println(\n",
    "    \"\"\"\n",
    "    | __  __ _____ ____   ____ ___\n",
    "    ||  \\/  | ____|  _ \\ / ___|_ _|\n",
    "    || |\\/| |  _| | |_) | |    | | \n",
    "    || |  | | |___|  _ <| |___ | | \n",
    "    ||_|  |_|_____|_| \\_\\\\____|___|\n",
    "    |\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
